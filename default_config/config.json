{
    "llama-2-7b-chat.Q4_K_M": {
        "prompt": "<|im_start|> system\n{system_prompt}\n<|im_end|>\n<|im_start|> user\n{user_prompt}\n<|im_end|>\n<|im_start|> assistant\n",
        "gpt4all_config": {
            "max_tokens": 4096,
            "n_predict": 2048,
            "stop": ["<|im_end|>"]
        }
    },
    "gpt4all-falcon-q4_0": {
        "prompt": "### Instruction: {system_prompt}\n{user_prompt}\n### Response:",
        "gpt4all_config": {
            "max_tokens": 4096,
            "n_predict": 2048,
            "stop": ["### Instruction:"]
        }
    },
    "leo-hessianai-13b-chat-bilingual.Q4_K_M": {
        "prompt": "<|im_start|> system\n{system_prompt}\n<|im_end|>\n<|im_start|> user\n{user_prompt}\n<|im_end|>\n<|im_start|> assistant\n",
        "gpt4all_config": {
            "max_tokens": 4096,
            "n_predict": 2048,
            "stop": ["<|im_end|>"]
        }
    },
    "neuralbeagle14-7b.Q4_K_M": {
        "prompt": "<|im_start|> system\n{system_prompt}\n<|im_end|>\n<|im_start|> user\n{user_prompt}\n<|im_end|>\n<|im_start|> assistant\n",
        "gpt4all_config": {
            "max_tokens": 8000,
            "n_predict": 4000,
            "stop": ["<|im_end|>"]
        }
    },
    "Meta-Llama-3-8B-Instruct.Q4_K_M": {
        "prompt": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n{user_prompt}<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
        "gpt4all_config": {
            "max_tokens": 8000,
            "n_predict": 4000,
            "stop": ["<|eot_id|>"]
        }
    },
    "Meta-Llama-3.1-8B-Instruct.Q4_K_M": {
        "prompt": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n{user_prompt}<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
        "gpt4all_config": {
            "max_tokens": 128000,
            "n_predict": 60000,
            "stop": ["<|eot_id|>"]
        }
    },
    "default": {
        "prompt": "<|im_start|> system\n{system_prompt}\n<|im_end|>\n<|im_start|> user\n{user_prompt}\n<|im_end|>\n<|im_start|> assistant\n",
        "gpt4all_config": {
            "max_tokens": 4096,
            "n_predict": 2048,
            "stop": ["<|im_end|>"]
        }
    }
}